{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is Machine Learning?\n",
    "Actually it's something like this.\n",
    "![alt text](images/xkcd.png \"xkcd Comic\")\n",
    "Source:xkcd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Why Bother to learn?\n",
    "Because... \n",
    "\n",
    "![alt text](images/meme.jpeg \"Meme Generation Using Deep Learning\")\n",
    "Source: Google Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Networks and Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What is a Neural Network?**\n",
    "Let's skip the definitions for which there's wikipedia at your disposal<br>\n",
    "**For now I'll say they are universal function approximators\"** <br>\n",
    "Have a look at this\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](images/neural_network.png)\n",
    "\n",
    "### Looks Familiar?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lets go deep."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](images/deep.png \"Meme Generation Using Deep Learning\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Neuron**: Biological Inspiration for Computation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "![biological_inspiration.png](images/biological_inspiration.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Supervised Learning with Neural Network**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "![application.jpeg](images/application.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression vs Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![reg_vs_class.png](images/reg_vs_class.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Wait a minute, What did you say? <br>\n",
    "Supervised, Unsupervised, What's that?**\n",
    "![suvsus.png](images/suvsus.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Why is DeepLearning taking off?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "![take_off.png](images/take_off.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**The vertical axes of the diagram you can see the performance of an algorithm (e.g. it’s prediction accuracy) and at the horizontal axes you can see the amount of data (Labelled Data).**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "You can also see that the performance of traditional learning algorithms (logistic Regression, SVM’s etc.) increases at the beginning with an increase of the amount of data but that it plateaus at a certain level and stops improving it’s performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The thing is that we have accumulated huge amounts of data over the last decades where our traditional learning algorithms can’t take advantage of, which is where Deep Learning comes into play."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Large Neural Networks (e.g. Deep Learning) are getting better and better the more data you put into them. Andrew NG, a leading AI scientist, said that the three main forces which improve Neural Networks are:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Data <br>**\n",
    "**2. Computation <br>**\n",
    "**3. Algorithms <br>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The recent breakthroughs in the development of algorithms are mostly due to making them run much faster than before, which makes it possible to use more and more data. For an example, a big advancement came from switching from a Sigmoid function (left picture) to a rectified-Linear-Unit function (right picture).**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![relu_sigmoid.png](images/relu_sigmoid.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The other reason why fast computation is important is that, the below cycle must be faster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![basic_cycle.png](images/basic_cycle.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Bringing more data to a model is almost always beneficial.**\n",
    "\n",
    "**Deep Learning approches improve with more data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Learning Representation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Representation.jpeg](images/Representation.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Learning\n",
    "### Aka. Here comes the exciting Part\n",
    "<img src=\"images/exc.jpg\" alt=\"Drawing\" style=\"width: 400px;\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![DeepLearning.png](images/DeepLearning.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Learning Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. CUDA\n",
    "2. Theno\n",
    "3. Caffe\n",
    "4. **Tensorflow 2.0**\n",
    "5. **Pytorch 1.0**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is Tensorflow?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![tensorflow.png](images/tensorflow.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Learning is Representation Learning\n",
    "                            (aka Feature Learning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Representation_learning.png](images/Representation_learning.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Representation_matters.png](images/Representation_matters.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WHY DEEP LEARNING?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![why_dl?.png](images/whydl.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is a Neural Network?\n",
    "**By the Example of House Price Prediction**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![house_pred_exmaple.png](images/house_pred_exmaple.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DeepLearning for human and machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![dl_human-machine.png](images/dl_human-machine.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![data_aug.png](images/data_aug.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Learning: Training and Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![training%20and%20testing.png](images/training%20and%20testing.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neuron : Forward pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/forward.png\" alt=\"Drawing\" style=\"height: 400px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Steps Involved in forward propagation!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![nn_are_parallelizable.png](images/nn_are_parallelizable.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How Neural Networks Learns : BackPropagation of Errors\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning is an Optimizing Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![optimization_problem.png](images/optimization_problem.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Different types of Activation function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![activation_fun.png](images/activation_fun.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![loss_func.png](images/loss_func.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "=================================================================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![MiniBatch.png](images/MiniBatch.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "=================================================================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Overfitting_regularization.png](images/Overfitting_regularization.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Overfitting2.png](images/Overfitting2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "=================================================================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regularization : 1. Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Regul_drop.png](images/Regul_drop.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.  Weight Penalty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![regul_weight_decay.png](images/regul_weight_decay.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "=================================================================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Norm.png](images/Norm.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Okay Enough!\n",
    "<img src=\"images/code.jpeg\" alt=\"Drawing\" style=\"width: 400px;\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's Code a neural Network from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np  \n",
    "#Define the Activation Function Sigmoid and its differential\n",
    "\n",
    "def sigmoid(t):\n",
    "    return 1/(1+np.exp(-t))\n",
    "\n",
    "def difsigmoid(d):\n",
    "    return d*(1-d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define a Neural Network Class\n",
    "class NN:\n",
    "    def __init__(self,x,y):\n",
    "        self.input= x\n",
    "        self.w1 = np.random.rand(self.input.shape[1],4)\n",
    "        self.w2 = np.random.rand(4,1)\n",
    "        self.y = y\n",
    "        self.output = np.zeros(y.shape)\n",
    "    \n",
    "    #Define the forward Pass\n",
    "    def ff(self):\n",
    "        self.l1 = sigmoid(np.dot(self.input,self.w1))\n",
    "        self.l2 = sigmoid(np.dot(self.l1, self.w2))\n",
    "        return self.l2\n",
    "    \n",
    "    #Define the Backward pass to backpropagate the errors\n",
    "    def backprop(self):\n",
    "        d_w2 = np.dot(self.l1.T,2*(self.y-self.output)*difsigmoid(self.output))\n",
    "        d_w1 = np.dot(self.input.T, np.dot(2*(self.y -self.output)*difsigmoid(self.output), self.w2.T)*difsigmoid(self.l1))\n",
    "        self.w1 += d_w1\n",
    "        self.w2 += d_w2\n",
    "    #Define the training step\n",
    "    def train(self,X,y):\n",
    "        self.output = self.ff()\n",
    "        self.backprop()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for iteration # 0\n",
      "\n",
      "The Loss is: \n",
      "0.3246295143337549\n",
      "\n",
      "\n",
      "for iteration # 1000\n",
      "\n",
      "The Loss is: \n",
      "0.0012707744468423224\n",
      "\n",
      "\n",
      "Final Training Loss is 0.127077 %\n"
     ]
    }
   ],
   "source": [
    "X=np.array(([0,0,1],[0,1,1],[1,0,1],[1,1,1]), dtype=float)\n",
    "y=np.array(([0],[1],[1],[0]), dtype=float)\n",
    "#Instantiate a neural network from our created Class.\n",
    "NN = NN(X,y)\n",
    "#Set our training Epochs\n",
    "epochs = 2000\n",
    "\n",
    "for i in range(epochs):\n",
    "    if i % 1000 ==0: \n",
    "        print (\"for iteration # \" + str(i) + \"\\n\")\n",
    "        l = np.mean(np.square(y - NN.ff()))\n",
    "        print (\"The Loss is: \\n\" + str(l)) # MSE LOSS\n",
    "        print (\"\\n\")\n",
    "    NN.train(X,y)\n",
    "l = np.around(l*100,decimals=6)\n",
    "print(f'Final Training Loss is {l} %')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network Playground"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://playground.tensorflow.org/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%html \n",
    "<iframe src=\"http://playground.tensorflow.org/\" width=\"1000\" height=\"600\"></iframe>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Sounds a lot?\n",
    "#### Here are some resources to aid You.\n",
    "1.[But what *is* a Neural Network? | Deep learning by 3Blue1Brown](https://www.youtube.com/watch?v=aircAruvnKk)  <br>\n",
    "2.[What is backpropagation really doing? | Deep learning by 3Blue1Brown](https://www.youtube.com/watch?v=Ilg3gGewQ5U) <br>\n",
    "3.[How the backpropagation algorithm works](http://neuralnetworksanddeeplearning.com/chap2.html)<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
